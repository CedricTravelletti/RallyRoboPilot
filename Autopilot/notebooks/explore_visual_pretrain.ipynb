{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c26ab3f9-6a1f-4155-bdca-ce3825c16061",
   "metadata": {},
   "source": [
    "# Explore pre-training data for visual model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c684ce1-69e4-4cb2-a58d-799c6ecfa5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b1ad74-5cdb-40af-90ec-25809b615364",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_path = os.path.join('../..', 'train_data', 'race_data_blue_1.pkl')\n",
    "\n",
    "# df = pd.read_pickle(processed_data_path)\n",
    "df_encoded = pd.read_pickle(\"../../train_data/blue_1/race_data_encoded.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d269008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_encoded.to_pickle(\"../../train_data/blue_1/race_data_encoded.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d23f71-c3cd-4835-a277-142f6ecd8da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatGPT below. \n",
    "def encode_single(record, columns):\n",
    "    \"\"\"\n",
    "    Encodes a single record (row) into an integer.\n",
    "    \n",
    "    Args:\n",
    "        record (dict): A dictionary containing the binary values for the columns.\n",
    "        columns (list): The list of column names to encode.\n",
    "    \n",
    "    Returns:\n",
    "        int: The encoded integer for the given record.\n",
    "    \"\"\"\n",
    "    return sum(record[col] * (1 << i) for i, col in enumerate(reversed(columns)))\n",
    "\n",
    "def decode_single(encoded_value, columns):\n",
    "    \"\"\"\n",
    "    Decodes an integer value into a dictionary of binary columns.\n",
    "    \n",
    "    Args:\n",
    "        encoded_value (int): The encoded integer value.\n",
    "        columns (list): The list of column names to decode.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary with the decoded binary values.\n",
    "    \"\"\"\n",
    "    num_columns = len(columns)\n",
    "    return {col: (encoded_value >> i) & 1 for i, col in enumerate(reversed(columns))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398dab2b-de7b-4bad-aca4-bc656fcdff4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_dataframe(df, columns):\n",
    "    \"\"\"\n",
    "    Encodes multiple binary columns into a single integer column for the entire DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame with binary columns.\n",
    "        columns (list): The list of column names to encode.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with an additional 'encoded' column.\n",
    "    \"\"\"\n",
    "    df['encoded'] = df[columns].apply(lambda row: encode_single(row.to_dict(), columns), axis=1)\n",
    "    return df\n",
    "\n",
    "def decode_dataframe(df, encoded_column, columns):\n",
    "    \"\"\"\n",
    "    Decodes an integer column into multiple binary columns for the entire DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame with the encoded column.\n",
    "        encoded_column (str): The name of the column with encoded integers.\n",
    "        columns (list): The list of column names to decode into.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with the decoded binary columns.\n",
    "    \"\"\"\n",
    "    decoded_columns = df[encoded_column].apply(lambda val: decode_single(val, columns))\n",
    "    decoded_df = pd.DataFrame(decoded_columns.tolist(), columns=columns, index=df.index)\n",
    "    return pd.concat([df, decoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9321dcf8-2b28-44d5-9788-244b9f533e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the column names\n",
    "# columns = ['up', 'down', 'left', 'right']\n",
    "\n",
    "# Encode\n",
    "# df_encoded = encode_dataframe(df, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dc6735-1b7a-4302-8866-e66a29dc185d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print distribution statistics\n",
    "print(df_encoded['encoded'].describe())\n",
    "\n",
    "# Plot distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "df_encoded['encoded'].plot(kind='hist', bins=50, edgecolor='black')\n",
    "plt.title('Distribution of Encoded Values')\n",
    "plt.xlabel('Encoded Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447bf144-9dab-4b91-a7e9-d8cb1d676c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_step = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # Move tensors to the configured device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                    .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "    # Validation\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in valid_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            del images, labels, outputs\n",
    "\n",
    "        print('Accuracy of the network on the {} validation images: {} %'.format(5000, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6e5083",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_transform = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ])\n",
    "data_folder = os.path.join('../..', 'train_data/blue_1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f45fca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Custom dataset class. Derived from the excellent tutoral at https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\"\"\"\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class BunchOfImagesDataset(Dataset):\n",
    "    def __init__(self, folder, transforms=None, batch_size=64):\n",
    "        self.folder = folder\n",
    "        self.files = glob.glob(os.path.join(folder, '*.png'))\n",
    "        self.transforms = transforms\n",
    "        self.labels = pd.read_pickle(os.path.join(folder, 'race_data_encoded.pkl'))\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = torch.tensor(int(self.labels.iloc[idx]['encoded'].item()))\n",
    "        img_id = idx # replace by indexing into the df.\n",
    "    \n",
    "        # img_path = self.files[idx]\n",
    "        # img_id = os.path.splitext(os.path.basename(img_path))[0]\n",
    "        img_path = os.path.join(self.folder, f'blue_1_id_{str(img_id).zfill(4)}.png')\n",
    "\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb6f193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the dataset\n",
    "dataset = BunchOfImagesDataset(data_folder, transforms=input_transform)\n",
    "dataloader = DataLoader(dataset, batch_size=16,\n",
    "                        shuffle=True, num_workers=0)\n",
    "\n",
    "\"\"\"\n",
    "# Query a bunch of data\n",
    "for i in range(5):  # Query first 5 samples\n",
    "    image, label = dataset[i]\n",
    "    print(f\"Image {i} - Label: {label}\")\n",
    "    plt.imshow(image.permute(1, 2, 0))  # Convert from (C, H, W) to (H, W, C)\n",
    "    plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2659f75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0673b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "num_classes = 16 # (forward, backward, left, right and all their combinations)\n",
    "\n",
    "# Load pre-trained model from timm\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True)\n",
    "\n",
    "# Modify the model head for fine-tuning\n",
    "num_features = model.classifier[-1].in_features\n",
    "# model.classifier[-1] = nn.Linear(num_features, num_classes)\n",
    "\n",
    "\"\"\"\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.5),               # Dropout layer with 50% probability\n",
    "    nn.Linear(num_features, 256),  # Additional linear layer with 256 output features\n",
    "    nn.ReLU(inplace=True),         # Activation function (you can choose other activation functions too)\n",
    "    nn.Dropout(0.5),               # Dropout layer with 50% probability\n",
    "    nn.Linear(256, num_classes)    # Final prediction fc layer\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7fd5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "num_epochs = 20\n",
    "batch_size = 16\n",
    "learning_rate = 0.005\n",
    "\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.005, momentum = 0.9)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4d31e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "total_step = len(dataloader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch} / {num_epochs}\")\n",
    "    for i, (images, labels) in enumerate(dataloader): \n",
    "        print(f\"Batch nr: {i}\") \n",
    "        # Move tensors to the configured device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                    .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "    \"\"\"\n",
    "    # Validation\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in valid_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            del images, labels, outputs\n",
    "\n",
    "        print('Accuracy of the network on the {} validation images: {} %'.format(5000, 100 * correct / total))\n",
    "    \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myDev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
